{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f9ed8c-2b9f-4401-b7da-875bad69cdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(46544) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (4.13.2)\n",
      "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!/opt/anaconda3/bin/python -m pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6c2df2-c6bb-4426-b32e-472bf16d91c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93080804-6099-4c74-a826-37ad0be93028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq \"unstructured[all-docs]\" pillow lxml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92bb98d-4dde-498d-a827-fb9ec26963d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json\n",
    "import docx\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "import signal\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4830510a-8d94-49da-a78c-378fccd71330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:11434/api/generate\"\n",
    "\n",
    "payload = {\n",
    "   \"model\": \"llama3.1\",\n",
    "  \"prompt\": \"Hello! Who are you?\",\n",
    "  \"stream\": False\n",
    "}\n",
    "\n",
    "try:\n",
    "   response = requests.post(url, json=payload)\n",
    "   response.raise_for_status()\n",
    "   result = response.json()\n",
    "   print(result[\"response\"])\n",
    "except requests.exceptions.RequestException as e:\n",
    "   print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98dc99b-cb83-4194-805f-b9d52d26d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/IDSWG/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "from llama_index.core.response_synthesizers import CompactAndRefine \n",
    "from llama_index.core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7de2bea-298a-467a-a77f-563c33133d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!brew install poppler tesseract libmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d1fd63-713b-4552-8b1b-cf82816421cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip uninstall -y charset_normalizer pdfminer.six unstructured unstructured-inference unstructured-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22816daf-2388-4cbb-8c77-31ef0d1e68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -Uq \"unstructured[all-docs]\" \"unstructured[pdf]\" pdfminer.six lxml Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5cf085e-49f3-4f8b-9d42-68615a096b71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'charset_normalizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/IDSWG/lib/python3.11/site-packages/unstructured/partition/pdf.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwrapt\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LTContainer, LTImage, LTItem, LTTextBox\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m open_filename\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpi_heif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_heif_opener\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/IDSWG/lib/python3.11/site-packages/pdfminer/layout.py:18\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Dict,\n\u001b[32m      5\u001b[39m     Generic,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     cast,\n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfcolor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFColorSpace\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFTypeError, PDFValueError\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdffont\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFFont\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/IDSWG/lib/python3.11/site-packages/pdfminer/pdfcolor.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpsparser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LIT\n\u001b[32m      6\u001b[39m LITERAL_DEVICE_GRAY = LIT(\u001b[33m\"\u001b[39m\u001b[33mDeviceGray\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m LITERAL_DEVICE_RGB = LIT(\u001b[33m\"\u001b[39m\u001b[33mDeviceRGB\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/IDSWG/lib/python3.11/site-packages/pdfminer/psparser.py:20\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     Any,\n\u001b[32m      7\u001b[39m     BinaryIO,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     Union,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m psexceptions, settings\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m choplist\n\u001b[32m     22\u001b[39m log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Adding aliases for these exceptions for backwards compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/IDSWG/lib/python3.11/site-packages/pdfminer/utils.py:31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LTComponent\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcharset_normalizer\u001b[39;00m  \u001b[38;5;66;03m# For str encoding detection\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# from sys import maxint as INF doesn't work anymore under Python3, but PDF\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# still uses 32 bits ints\u001b[39;00m\n\u001b[32m     35\u001b[39m INF = (\u001b[32m1\u001b[39m << \u001b[32m31\u001b[39m) - \u001b[32m1\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'charset_normalizer'"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8372d52-682f-4a52-8602-191f9fda7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docx(file_path):\n",
    "    \"\"\"Extracts text from a DOCX file.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        for paragraph in doc.paragraphs:\n",
    "            text += paragraph.text + \"\\n\"\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: DOCX file not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from DOCX: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5af0577-2203-44f8-98e2-e7c12f382213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_document_content(file_path):\n",
    "    \"\"\"\n",
    "    Reads text from a PDF or DOCX file based on its extension.\n",
    "    Returns the extracted text as a string.\n",
    "    \"\"\"\n",
    "    if file_path.lower().endswith('.docx'):\n",
    "        return extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please provide a .pdf or .docx file.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c95358-fccc-439d-bfd7-d19b8ed9dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "Settings.llm = Ollama(model=\"llama3.1\", request_timeout=200.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc4edadc-3f04-4abd-a5bb-73e238358f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeout_context(seconds):\n",
    "    \"\"\"Context manager for timeout handling\"\"\"\n",
    "    def timeout_handler(signum, frame):\n",
    "        raise TimeoutError(f\"Operation timed out after {seconds} seconds\")\n",
    "    \n",
    "    # Set the signal handler and alarm\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(seconds)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ba7af9-93c1-4f58-852a-6555fe7d16a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document: /Users/Sravya/Desktop/AI_model_table_shells/Table shell standard.docx\n",
      "\n",
      "--- Document Content Extracted (partial view) ---\n",
      "\n",
      "Table 14.1.2.1: Demographic and Baseline Characteristics\n",
      "Full Analysis Set\n",
      "\n",
      "Notes: The baseline value is defined as the last non-missing value before initial administration of study drug.\n",
      "[a] Age in years is calculated using the date of birth and date of informed consent.\n",
      "Source Data: adam.adsl; Listing 16.2.4.x.x.\n",
      ". Table 14.1.2.1: Demographic and Baseline Characteristics\n",
      "Full Analysis Set\n",
      "\n",
      "Notes: The baseline value is defined as the last non-missing value before initial administration of stud...\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Setting up RAG Pipeline ---\n",
      "Created LlamaIndex Document object.\n",
      "Creating VectorStoreIndex (this involves embedding the document)...\n",
      "VectorStoreIndex created.\n",
      "Creating QueryEngine...\n",
      "QueryEngine created.\n",
      "\n",
      "--- Running Queries with RAG ---\n",
      "--- Query 1: Give me the height table ---\n",
      "LLM Response (attempted JSON):\n",
      "Could not parse as JSON. Raw response:\n",
      "{{\n",
      "  \"Height (cm)\": {{\n",
      "    \"n\": {{ \"Treatment A\": \"123\", \"Treatment B\": \"456\", \"Total\": \"579\" }},\n",
      "    \"Mean\": {{ \"Treatment A\": \"170.12\", \"Treatment B\": \"168.75\", \"Total\": \"169.44\" }},\n",
      "    \"Standard Deviation\": {{ \"Treatment A\": \"6.32\", \"Treatment B\": \"5.91\", \"Total\": \"6.12\" }},\n",
      "    \"Median\": {{ \"Treatment A\": \"170.00\", \"Treatment B\": \"168.50\", \"Total\": \"169.00\" }},\n",
      "    \"Min, Max\": {{ \"Treatment A\": \"150, 190\", \"Treatment B\": \"155, 185\", \"Total\": \"145, 195\" }}\n",
      "  }}\n",
      "}}\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    base_directory_path = \"/Users/Sravya/Desktop/AI_model_table_shells\"\n",
    "    file_name = \"Table shell standard.docx\" # Make sure this matches your file\n",
    "\n",
    "    file_path = os.path.join(base_directory_path, file_name)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: Document file not found at {file_path}. Please ensure the file exists and the 'file_name' variable is correct.\")\n",
    "        \n",
    "    print(f\"Reading document: {file_path}\")\n",
    "    document_content_text = read_document_content(file_path)\n",
    "\n",
    "    if document_content_text:\n",
    "        print(\"\\n--- Document Content Extracted (partial view) ---\")\n",
    "        print(document_content_text[:500] + \"...\" if len(document_content_text) > 500 else document_content_text)\n",
    "        print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"--- Setting up RAG Pipeline ---\")\n",
    "\n",
    "        document_for_rag = Document(text=document_content_text)\n",
    "        print(\"Created LlamaIndex Document object.\")\n",
    "\n",
    "        print(\"Creating VectorStoreIndex (this involves embedding the document)...\")\n",
    "        index = VectorStoreIndex.from_documents([document_for_rag], embed_model=Settings.embed_model)\n",
    "        print(\"VectorStoreIndex created.\")\n",
    "\n",
    "        print(\"Creating QueryEngine...\")\n",
    "        \n",
    "        # --- ADJUSTED CUSTOM_QA_TEMPLATE ---\n",
    "        # Define the template string\n",
    "        custom_qa_template_str = \"\"\"Context information is below.\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context information, answer the query.\n",
    "\n",
    "If the query asks for a general characteristic (e.g., \"height\", \"weight\", \"ethnicity\"), provide all associated metrics (e.g., 'n', 'Mean', 'Standard Deviation', 'Median', 'Min, Max' for height/weight) and their values across all relevant columns ('Treatment A', 'Treatment B', 'Total'), strictly in JSON format. Organize the JSON by the characteristic, then by metric, then by column.\n",
    "\n",
    "If the query asks for a specific metric or cell value (e.g., \"Mean height for Treatment A\", \"Q1 Sales for Product A\"), provide only that specific value in JSON.\n",
    "\n",
    "If you cannot find the information, return an empty JSON object {{}}.\n",
    "\n",
    "Example JSON for a general characteristic query (e.g., \"height\"):\n",
    "{{\n",
    "  \"Height (cm)\": {{\n",
    "    \"n\": {{ \"Treatment A\": \"xx\", \"Treatment B\": \"xx\", \"Total\": \"xx\" }},\n",
    "    \"Mean\": {{ \"Treatment A\": \"xxx.xx\", \"Treatment B\": \"xxx.xx\", \"Total\": \"xxx.xx\" }},\n",
    "    \"Standard Deviation\": {{ \"Treatment A\": \"xxx.xxx\", \"Treatment B\": \"xxx.xxx\", \"Total\": \"xxx.xxx\" }},\n",
    "    \"Median\": {{ \"Treatment A\": \"xxx.xx\", \"Treatment B\": \"xxx.xx\", \"Total\": \"xxx.xx\" }},\n",
    "    \"Min, Max\": {{ \"Treatment A\": \"xxx, xxx\", \"Treatment B\": \"xxx, xxx\", \"Total\": \"xxx, xxx\" }}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Example JSON for a specific metric query: {{\"Mean height for Treatment A\": \"xxx.xx\"}}\n",
    "\n",
    "Query: {query_str}\n",
    "\"\"\"\n",
    "        # Wrap the string in a PromptTemplate object\n",
    "        custom_qa_template = PromptTemplate(custom_qa_template_str)\n",
    "        \n",
    "        query_engine = index.as_query_engine(\n",
    "            llm=Settings.llm,\n",
    "            response_synthesizer=CompactAndRefine(text_qa_template=custom_qa_template)\n",
    "        )\n",
    "        print(\"QueryEngine created.\")\n",
    "\n",
    "        # --- Example Queries (Adjusted for the new output expectation) ---\n",
    "        queries = [\n",
    "            \"Give me the height table\", # General characteristic query\n",
    "        ]\n",
    "\n",
    "        print(\"\\n--- Running Queries with RAG ---\")\n",
    "        for i, query_text in enumerate(queries):\n",
    "            print(f\"--- Query {i+1}: {query_text} ---\")\n",
    "            \n",
    "            try:\n",
    "                response = query_engine.query(query_text)\n",
    "                llm_response_text = response.response\n",
    "                \n",
    "                print(\"LLM Response (attempted JSON):\")\n",
    "                try:\n",
    "                    parsed_json = json.loads(llm_response_text)\n",
    "                    print(json.dumps(parsed_json, indent=2))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Could not parse as JSON. Raw response:\")\n",
    "                    print(llm_response_text)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error during query {i+1}: {e}\")\n",
    "            print(\"------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc3089-2331-4639-9bf6-59cf0a5d3582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
