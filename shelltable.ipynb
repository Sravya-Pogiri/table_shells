{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f9ed8c-2b9f-4401-b7da-875bad69cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/opt/anaconda3/bin/python -m pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6c2df2-c6bb-4426-b32e-472bf16d91c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93080804-6099-4c74-a826-37ad0be93028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -Uq \"unstructured[all-docs]\" pillow lxml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92bb98d-4dde-498d-a827-fb9ec26963d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json\n",
    "import docx\n",
    "import pypdf\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "import signal\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4830510a-8d94-49da-a78c-378fccd71330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:11434/api/generate\"\n",
    "\n",
    "payload = {\n",
    "   \"model\": \"llama3.1\",\n",
    "  \"prompt\": \"Hello! Who are you?\",\n",
    "  \"stream\": False\n",
    "}\n",
    "\n",
    "try:\n",
    "   response = requests.post(url, json=payload)\n",
    "   response.raise_for_status()\n",
    "   result = response.json()\n",
    "   print(result[\"response\"])\n",
    "except requests.exceptions.RequestException as e:\n",
    "   print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98dc99b-cb83-4194-805f-b9d52d26d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/IDSWG/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "from llama_index.core.response_synthesizers import CompactAndRefine \n",
    "from llama_index.core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7de2bea-298a-467a-a77f-563c33133d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!brew install poppler tesseract libmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d1fd63-713b-4552-8b1b-cf82816421cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip uninstall -y charset_normalizer pdfminer.six unstructured unstructured-inference unstructured-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22816daf-2388-4cbb-8c77-31ef0d1e68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -Uq \"unstructured[all-docs]\" \"unstructured[pdf]\" pdfminer.six lxml Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5cf085e-49f3-4f8b-9d42-68615a096b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(63843) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cf86c99-e016-467f-8200-6959889a2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install 'huggingface_hub[hf_xet]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5233001c-bcc4-4a76-82b2-d994b77e271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(63844) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63845) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63846) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63861) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63862) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63863) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63864) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
      "python(63866) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63872) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63873) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63874) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63875) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63876) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63877) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63878) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63879) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63880) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63881) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63882) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63883) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63884) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63891) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63892) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63893) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63894) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63895) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63896) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63897) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63898) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63899) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63900) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63901) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63902) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63903) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63904) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63905) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63906) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63913) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63914) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(63915) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "chunks = partition_pdf(\n",
    "    filename='/Users/Sravya/Desktop/AI_model_table_shells/Table shell standard.pdf',\n",
    "    infer_table_structure=True,            # extract tables\n",
    "    strategy=\"hi_res\",                     # mandatory to infer tables\n",
    "\n",
    "    extract_image_block_types=[\"Image\"],   # Add 'Table' to list to extract image of tables\n",
    "    # image_output_dir_path=output_path,   # if None, images and tables will saved in base64\n",
    "\n",
    "    extract_image_block_to_payload=True,   # if true, will extract base64 for API usage\n",
    "\n",
    "    chunking_strategy=\"by_title\",          # or 'basic'\n",
    "    max_characters=10000,                  # defaults to 500\n",
    "    combine_text_under_n_chars=2000,       # defaults to 0\n",
    "    new_after_n_chars=6000,\n",
    "\n",
    "    # extract_images_in_pdf=True,          # deprecated\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a5d67f-f4d5-416a-b161-99582a385111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf_simple(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file page by page.\n",
    "    Note: This is a simple text extraction and might not preserve complex layouts\n",
    "    or table structures as effectively as 'unstructured'.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        reader = pypdf.PdfReader(file_path)\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text() + \"\\n\" # Add newline between pages\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: PDF file not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8372d52-682f-4a52-8602-191f9fda7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docx(file_path):\n",
    "    \"\"\"Extracts text from a DOCX file.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        for paragraph in doc.paragraphs:\n",
    "            text += paragraph.text + \"\\n\"\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: DOCX file not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from DOCX: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5af0577-2203-44f8-98e2-e7c12f382213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_document_content(file_path):\n",
    "    \"\"\"\n",
    "    Reads text from a PDF or DOCX file based on its extension using unstructured.\n",
    "    Returns the extracted text as a string.\n",
    "    \"\"\"\n",
    "    elements = []\n",
    "    try:\n",
    "        if file_path.lower().endswith('.docx'):\n",
    "            print(\"Using unstructured.partition_docx for DOCX file...\")\n",
    "            elements = partition_docx(\n",
    "                filename=file_path,\n",
    "                infer_table_structure=True,\n",
    "            )\n",
    "        elif file_path.lower().endswith('.pdf'): # <-- This branch is for PDFs\n",
    "            print(\"Using unstructured.partition_pdf for PDF file...\")\n",
    "            elements = partition_pdf(\n",
    "                filename=file_path,\n",
    "                infer_table_structure=True, # <-- Key for table extraction\n",
    "                strategy=\"hi_res\",\n",
    "                extract_image_block_types=[\"Image\"],\n",
    "                extract_image_block_to_payload=True,\n",
    "                chunking_strategy=\"by_title\",\n",
    "                max_characters=10000,\n",
    "                combine_text_under_n_chars=2000,\n",
    "                new_after_n_chars=6000,\n",
    "            )\n",
    "        else:\n",
    "            print(\"Unsupported file format. Please provide a .pdf or .docx file.\")\n",
    "            return None\n",
    "\n",
    "        # This joins the text content of all elements, including table text\n",
    "        # (which unstructured will convert from the inferred table structure).\n",
    "        full_text = \"\\n\\n\".join([str(el.text) for el in elements if el.text])\n",
    "        return full_text\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting content from {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c95358-fccc-439d-bfd7-d19b8ed9dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(63932) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "Settings.llm = Ollama(model=\"mistral\", request_timeout=200.0, format = \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc4edadc-3f04-4abd-a5bb-73e238358f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager # <--- Add this decorator!\n",
    "def timeout_context(seconds):\n",
    "    \"\"\"Context manager for timeout handling\"\"\"\n",
    "    def timeout_handler(signum, frame):\n",
    "        raise TimeoutError(f\"Operation timed out after {seconds} seconds\")\n",
    "\n",
    "    # Set the signal handler and alarm\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(seconds)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70ba7af9-93c1-4f58-852a-6555fe7d16a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document: /Users/Sravya/Desktop/AI_model_table_shells/Table shell standard.pdf\n",
      "Using unstructured.partition_pdf for PDF file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(64295) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64296) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64297) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64316) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64317) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64318) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64320) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64324) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64328) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64329) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64330) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64331) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64332) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64333) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64334) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64335) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64336) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64337) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64338) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64339) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64341) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64348) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64349) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64350) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64351) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64352) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64353) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64354) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64355) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64356) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64357) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64358) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64359) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64360) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64361) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64362) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64366) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64370) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64371) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(64372) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Document Content Extracted (partial view) ---\n",
      "Table 14.1.2.1: Demographic and Baseline Characteristics Full Analysis Set\n",
      "\n",
      "Characteristics Treatment A (N=xxx) Ethnicity [for US studies only] Hispanic/Latino xx (xx.x) Non-Hispanic/Non-Latino xx (xx.x) Unknown xx (xx.x) Height (cm) n xx Mean xxx.xx Standard Deviation xxx.xxx Median xxx.xx Min, Max xxx, xxx Weight (kg) n xx Mean xxx.xx Standard Deviation xxx.xxx Median xxx.xx Min, Max xxx, xxx Body Mass Index (kg/m2) n xx Mean xxx.xx Standard Deviation xxx.xxx Median xxx.xx Treatment B (N=xxx) ...\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Setting up RAG Pipeline ---\n",
      "Created LlamaIndex Document object.\n",
      "Creating VectorStoreIndex (this involves embedding the document)...\n",
      "VectorStoreIndex created.\n",
      "Creating QueryEngine...\n",
      "QueryEngine created.\n",
      "\n",
      "--- Running Queries with RAG ---\n",
      "--- Query 1: Give me the height table ---\n",
      "\n",
      "--- Height (cm) Table ---\n",
      "| Treatment / Statistic   | Treatment A   | Treatment B   | Total    |\n",
      "|:------------------------|:--------------|:--------------|:---------|\n",
      "| n                       | xx            | xx            | xx       |\n",
      "| Mean                    | xxx.xx        | xxx.xx        | xxx.xx   |\n",
      "| Standard Deviation      | xxx.xxx       | xxx.xxx       | xxx.xxx  |\n",
      "| Median                  | xxx.xx        | xxx.xx        | xxx.xx   |\n",
      "| Min, Max                | xxx, xxx      | xxx, xxx      | xxx, xxx |\n",
      "-----------------------------------\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    base_directory_path = \"/Users/Sravya/Desktop/AI_model_table_shells\"\n",
    "    file_name = \"Table shell standard.pdf\" # Make sure this matches your file\n",
    "\n",
    "    file_path = os.path.join(base_directory_path, file_name)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: Document file not found at {file_path}. Please ensure the file exists and the 'file_name' variable is correct.\")\n",
    "        exit() # Exit if file not found\n",
    "\n",
    "    print(f\"Reading document: {file_path}\")\n",
    "    document_content_text = read_document_content(file_path)\n",
    "\n",
    "    if document_content_text:\n",
    "        print(\"\\n--- Document Content Extracted (partial view) ---\")\n",
    "        print(document_content_text[:500] + \"...\" if len(document_content_text) > 500 else document_content_text)\n",
    "        print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"--- Setting up RAG Pipeline ---\")\n",
    "\n",
    "        document_for_rag = Document(text=document_content_text)\n",
    "        print(\"Created LlamaIndex Document object.\")\n",
    "\n",
    "        print(\"Creating VectorStoreIndex (this involves embedding the document)...\")\n",
    "        index = VectorStoreIndex.from_documents([document_for_rag], embed_model=Settings.embed_model)\n",
    "        print(\"VectorStoreIndex created.\")\n",
    "\n",
    "        print(\"Creating QueryEngine...\")\n",
    "\n",
    "        # --- ADJUSTED CUSTOM_QA_TEMPLATE: FIXED SPECIFIC METRIC EXAMPLE ---\n",
    "        custom_qa_template_str = \"\"\"Context information is below.\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context information, answer the query.\n",
    "\n",
    "**IMPORTANT: Your response MUST be valid JSON and contain ONLY the JSON object. Do NOT include any conversational text, explanations, or markdown fences (```json).**\n",
    "\n",
    "If the query asks for a general characteristic (e.g., \"height\", \"weight\", \"ethnicity\"), provide all associated metrics (e.g., 'n', 'Mean', 'Standard Deviation', 'Median', 'Min, Max' for height/weight) and their values across all relevant columns ('Treatment A', 'Treatment B', 'Total'), strictly in JSON format. Organize the JSON by the characteristic, then by metric, then by column.\n",
    "\n",
    "If the query asks for a specific metric or cell value (e.g., \"Mean height for Treatment A\", \"Q1 Sales for Product A\"), provide only that specific value in JSON.\n",
    "\n",
    "If you cannot find the information, return an empty JSON object {{}}.\n",
    "\n",
    "Example JSON for a single general characteristic query (e.g., \"height\"):\n",
    "{{\n",
    "  \"Height (cm)\": {{\n",
    "    \"n\": {{ \"Treatment A\": \"xx\", \"Treatment B\": \"xx\", \"Total\": \"xx\" }},\n",
    "    \"Mean\": {{ \"Treatment A\": \"xxx.xx\", \"Treatment B\": \"xxx.xx\", \"Total\": \"xxx.xx\" }},\n",
    "    \"Standard Deviation\": {{ \"Treatment A\": \"xxx.xxx\", \"Treatment B\": \"xxx.xxx\", \"Total\": \"xxx.xxx\" }},\n",
    "    \"Median\": {{ \"Treatment A\": \"xxx.xx\", \"Treatment B\": \"xxx.xx\", \"Total\": \"xxx.xx\" }},\n",
    "    \"Min, Max\": {{ \"Treatment A\": \"xxx, xxx\", \"Treatment B\": \"xxx, xxx\", \"Total\": \"xxx, xxx\" }}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Example JSON for multiple general characteristics query (e.g., \"height and weight\"):\n",
    "{{\n",
    "  \"Height (cm)\": {{\n",
    "    \"n\": {{ \"Treatment A\": \"xx\", \"Treatment B\": \"xx\", \"Total\": \"xx\" }},\n",
    "    \"Mean\": {{ \"Treatment A\": \"xxx.xx\", \"Treatment B\": \"xxx.xx\", \"Total\": \"xxx.xx\" }}\n",
    "  }},\n",
    "  \"Weight (kg)\": {{\n",
    "    \"n\": {{ \"Treatment A\": \"xx\", \"Treatment B\": \"xx\", \"Total\": \"xx\" }},\n",
    "    \"Mean\": {{ \"Treatment A\": \"xxx.xx\", \"Treatment B\": \"xxx.xx\", \"Total\": \"xxx.xx\" }}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Example JSON for a specific metric query: {\"Mean height for Treatment A\": \"xxx.xx\"} # <--- FIXED HERE!\n",
    "\n",
    "Query: {query_str}\n",
    "\"\"\"\n",
    "        # Wrap the string in a PromptTemplate object\n",
    "        custom_qa_template = PromptTemplate(custom_qa_template_str)\n",
    "\n",
    "        query_engine = index.as_query_engine(\n",
    "            llm=Settings.llm,\n",
    "            response_synthesizer=CompactAndRefine(text_qa_template=custom_qa_template),\n",
    "            similarity_top_k=2 # Limit chunks for potentially faster LLM processing\n",
    "        )\n",
    "        print(\"QueryEngine created.\")\n",
    "\n",
    "        queries = [\n",
    "            \"Give me the height table\", # Query that should return multiple characteristics\n",
    "            \n",
    "        ]\n",
    "\n",
    "        print(\"\\n--- Running Queries with RAG ---\")\n",
    "        for i, query_text in enumerate(queries):\n",
    "            print(f\"--- Query {i+1}: {query_text} ---\")\n",
    "\n",
    "            try:\n",
    "                with timeout_context(600): # Using your defined timeout_context\n",
    "                    response = query_engine.query(query_text)\n",
    "                    llm_response_text = response.response\n",
    "\n",
    "                # REMOVED DEBUG PRINTS FOR RAW AND PARSED JSON HERE\n",
    "                # print(\"Raw LLM Response before parsing:\")\n",
    "                # print(repr(llm_response_text)) # Use repr to see hidden chars like \\n\n",
    "\n",
    "                # Strip whitespace and markdown fences if present\n",
    "                llm_response_text = llm_response_text.strip()\n",
    "                if llm_response_text.startswith(\"```json\") and llm_response_text.endswith(\"```\"):\n",
    "                    llm_response_text = llm_response_text[len(\"```json\"):-len(\"```\")].strip()\n",
    "\n",
    "                try:\n",
    "                    parsed_json = json.loads(llm_response_text)\n",
    "\n",
    "                    # REMOVED DEBUG PRINTS FOR RAW AND PARSED JSON HERE\n",
    "                    # print(\"\\nParsed JSON structure:\")\n",
    "                    # print(json.dumps(parsed_json, indent=2))\n",
    "                    # print(\"-\" * 30)\n",
    "\n",
    "                    # --- MODIFIED LOGIC TO PROCESS AND PRINT MULTIPLE TABLES ---\n",
    "                    if isinstance(parsed_json, dict) and len(parsed_json) > 0:\n",
    "                        processed_at_least_one_item = False\n",
    "                        for characteristic_name, characteristic_data in parsed_json.items():\n",
    "                            # Check if the 'characteristic_data' is a dictionary AND contains\n",
    "                            # at least one value that is also a dictionary (indicating nested structure for a table)\n",
    "                            if isinstance(characteristic_data, dict) and \\\n",
    "                               any(isinstance(v, dict) for v in characteristic_data.values()):\n",
    "\n",
    "                                try:\n",
    "                                    df = pd.DataFrame(characteristic_data).T # Transpose for desired row/column layout\n",
    "                                    df.index.name = \"Treatment / Statistic\"\n",
    "                                    df.columns.name = characteristic_name\n",
    "\n",
    "                                    print(f\"\\n--- {characteristic_name} Table ---\")\n",
    "                                    print(tabulate(df, headers='keys', tablefmt='pipe', showindex=True))\n",
    "                                    print(f\"-----------------------------------\")\n",
    "                                    processed_at_least_one_item = True\n",
    "                                except Exception as df_error:\n",
    "                                    print(f\"Could not format '{characteristic_name}' as a table due to error: {df_error}\")\n",
    "                                    # print(f\"Raw data for '{characteristic_name}': {json.dumps(characteristic_data, indent=2)}\") # Debug if needed\n",
    "\n",
    "                            # This handles simple key-value pairs at the top level\n",
    "                            # (e.g., {\"Mean height for Treatment A\": \"xxx.xx\"}) that might be returned alongside or alone.\n",
    "                            elif isinstance(characteristic_data, (str, int, float, bool, type(None))): # Check for simple types (not nested dict)\n",
    "                                print(f\"\\n--- Specific Metric or Simple JSON ---\")\n",
    "                                # If it's a specific metric, it might be a single key-value at the top level\n",
    "                                # So, present it nicely without iterating\n",
    "                                print(json.dumps(parsed_json, indent=2)) # Print the whole parsed_json if it's a simple flat dict\n",
    "                                print(f\"-----------------------------------\")\n",
    "                                processed_at_least_one_item = True\n",
    "                                break # Exit loop, as this is typically the only item for specific metric queries\n",
    "                            else:\n",
    "                                # This covers cases where characteristic_data is a dict but doesn't fit the nested table format\n",
    "                                # e.g., {\"Ethnicity\": {\"Hispanic/Latino\": \"xx\", \"Non-Hispanic\": \"xx\"}} - could be a simple table too!\n",
    "                                print(f\"\\n--- Unrecognized but valid JSON structure for '{characteristic_name}' ---\")\n",
    "                                print(json.dumps({characteristic_name: characteristic_data}, indent=2))\n",
    "                                print(f\"-----------------------------------\")\n",
    "                                processed_at_least_one_item = True\n",
    "\n",
    "                        if not processed_at_least_one_item:\n",
    "                             # This catches cases where JSON is valid but doesn't fit expected table/simple-metric patterns\n",
    "                             # E.g., {} or {\"some_key\": \"some_value_not_dict_or_nested_dict\"}\n",
    "                             print(\"LLM returned valid JSON but no recognized table or specific metric format.\")\n",
    "                             print(json.dumps(parsed_json, indent=2))\n",
    "                    else:\n",
    "                        print(\"LLM returned an empty or unexpected JSON format.\")\n",
    "                        print(llm_response_text) # Print raw if not recognized JSON\n",
    "                    # --- END MODIFIED LOGIC ---\n",
    "\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Could not parse as JSON. Raw response:\\n{llm_response_text}\\nError: {e}\")\n",
    "\n",
    "            except TimeoutError as te:\n",
    "                print(f\"Query timed out: {te}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error during query {i+1}: {e}\")\n",
    "            print(\"------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28580dff-ac83-43da-ae3e-37d44d607422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
